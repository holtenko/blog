![](https://cdn.nlark.com/yuque/0/2022/jpeg/1193004/1660741440403-2a0557fd-19ed-4a81-8bc0-6bab73933bab.jpeg)
# Redis
```
docker run --name=redis \
--restart=always \
-d \
-p 6379:6379 \
-v /docker/redis/conf/redis.conf:/etc/redis/redis.conf \
-v /docker/redis/data:/data \
redis redis-server /etc/redis/redis.conf

redis.conf
-----
port 6379
masterauth holten2Redis
requirepass holten2Redis
appendonly yes
```
# Zookeeper
```
docker run \
--restart always \
--name zookeeper \
-d \
-v /docker/zookeeper/data:/opt/zookeeper/data \
-p 2181:2181 \
zookeeper
```
# Kafka
```
docker pull bitnami/kafka:3.2.1

docker run \
--name kafka \
--restart=always \
-d \
-p 9092:9092 \
-e KAFKA_ZOOKEEPER_CONNECT=zk.septbits.com:2181/kafka \
-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.50.201:9092 \
-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \
-e ALLOW_PLAINTEXT_LISTENER=yes \
-v /etc/localtime:/etc/localtime \
-v /etc/hosts:/etc/hosts \
bitnami/kafka:3.2.1
```
# Nacos
```
docker run \
  --name nacos \
  --restart=always \
  -d \
  -p 8848:8848 \
  -p 8849:8849 \
  -p 9848:9848 \
  -p 9849:9849 \
  -e MODE=standalone \
  -e SPRING_DATASOURCE_PLATFORM=mysql \
  -e MYSQL_SERVICE_HOST=db.septbits.com \
  -e MYSQL_SERVICE_PORT=3306 \
  -e MYSQL_SERVICE_DB_NAME=nacos_config \
  -e MYSQL_SERVICE_USER=holten \
  -e MYSQL_SERVICE_PASSWORD=holten2MySQL! \
  -e NACOS_USER=holten \
  -e NACOS_PASSWORD=ilak8865 \
  -e JVM_XMS=512m \
  -e JVM_XMX=512m \
  -e JVM_XMN=256m \
  -e JVM_MS=32m \
  -e JVM_MMS=80m \
  -v /etc/hosts:/etc/hosts \
  nacos/nacos-server:v2.1.0
```
# ElasticSearch
```
docker run \
-itd \
--name es \
--restart=always \
-p 9200:9200 \
-e "discovery.type=single-node" \
-e ES_JAVA_OPTS="-Xms1g -Xmx1g" \
-v /docker/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \
-v /docker/es/data:/usr/share/elasticsearch/data \
-v /docker/es/plugins:/usr/share/elasticsearch/plugins \
-v /docker/es/logs:/usr/share/elasticsearch/logs \
elasticsearch:7.17.5

echo "http.host: 0.0.0.0" >> /docker/es/config/elasticsearch.yml
```
```
docker pull kibana:7.17.5

docker run \
--name kibana \
--restart=always \
-e ELASTICSEARCH_HOSTS=http://es.septbits.com:9200 \
-p 5601:5601 \
-v /etc/hosts:/etc/hosts \
-d \
kibana:7.17.5
```
# Prometheus
```
docker run -itd --name prometheus \
--restart=always \
-p 9090:9090 \
-v /docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \
prom/prometheus:v2.37.0

# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]
```
```
docker run -itd --name grafana \
--restart=always \
-p 3000:3000 \
-v /docker/grafana:/var/lib/grafana \
-v /etc/hosts:/etc/hosts \
grafana/grafana:9.0.6
```
```
docker run \
-itd --name opentelemetry \
--restart=always \
-v /docker/opentelemetry/config.yaml:/etc/otelcol/config.yaml \
otel/opentelemetry-collector:0.50.0

extensions:
  health_check:
# A receiver is how data gets into the OpenTelemetry Collector
receivers:
  # Set Prometheus Receiver to collects metrics from targets
  # It’s supports the full set of Prometheus configuration
  prometheus:
    config:
      scrape_configs:
        - job_name: 'vm-monitoring'
          scrape_interval: 10s
          static_configs:
              # Replace the IP to your VMs‘s IP which has installed Node Exporter
            - targets: [ '192.168.50.100:9100' ]
            - targets: [ '192.168.50.201:9100' ]
            - targets: [ '192.168.50.202:9100' ]

processors:
  batch:

# An exporter is how data gets sent to different systems/back-ends
exporters:
  # Exports metrics via gRPC using OpenCensus format
  opencensus:
    endpoint: "192.168.50.100:11800" # The OAP Server address
    tls:
      insecure: true
  logging:
    logLevel: debug

service:
  pipelines:
    metrics:
      receivers: [prometheus]
      processors: [batch]
      exporters: [logging, opencensus]

  extensions: [health_check]
```
# Apollo 
```
// Config Service
docker run \
    --name apollo-configservice \
    --restart=always \
    -e SPRING_DATASOURCE_URL="jdbc:mysql://db.septbits.com:3306/ApolloConfigDB?characterEncoding=utf8" \
    -e SPRING_DATASOURCE_USERNAME=holten -e SPRING_DATASOURCE_PASSWORD=holten2MySQL! \
    -d \
    -p 8080:8080 \
    -v /docker/apollo/configservice/logs:/opt/logs \
    -v /etc/hosts:/etc/hosts \
    apolloconfig/apollo-configservice:2.0.1

// Admin Service
docker run \
    --name apollo-adminservice \
    --restart=always \
    -e SPRING_DATASOURCE_URL="jdbc:mysql://db.septbits.com:3306/ApolloConfigDB?characterEncoding=utf8" \
    -e SPRING_DATASOURCE_USERNAME=holten -e SPRING_DATASOURCE_PASSWORD=holten2MySQL! \
    -d \
    -p 8090:8090 \
    -v /docker/apollo/adminservice/logs:/opt/logs \
    -v /etc/hosts:/etc/hosts \
    apolloconfig/apollo-adminservice:2.0.1
    
docker run \
    --name apollo-portal \
    --restart=always \
    -e SPRING_DATASOURCE_URL="jdbc:mysql://db.septbits.com:3306/ApolloPortalDB?characterEncoding=utf8" \
    -e SPRING_DATASOURCE_USERNAME=holten -e SPRING_DATASOURCE_PASSWORD=holten2MySQL! \
    -e APOLLO_PORTAL_ENVS=dev \
    -e DEV_META=http://apollo.septbits.com:8080 \
    -d \
    -p 8070:8070 \
    -v /docker/apollo/portal/logs:/opt/logs \
    -v /etc/hosts:/etc/hosts \
    apolloconfig/apollo-portal:2.0.1
```
# skywalking
```
docker run \
  --name skywalking-oap \
  --network=host \
  --restart=always \
  -d \
  -e TZ=Asia/Shanghai \
  -v /docker/skywalking/conf/application.yml:/skywalking/config/application.yml \
  apache/skywalking-oap-server:9.1.0
  
docker run \
--name skywalking-ui \
--restart always \
-d \
-e TZ=Asia/Shanghai \
-e SW_OAP_ADDRESS=http://192.168.50.100:12800 \
-p 8080:8080 \
apache/skywalking-ui:9.1.0
```
# Shenyu
```
docker run \
--name shenyu-admin \
--network=host \
--restart always \
-v /docker/shenyu/admin/ext-lib:/opt/shenyu-admin/ext-lib \
-v /docker/shenyu/admin/conf:/opt/shenyu-admin/conf \
-d \
apache/shenyu-admin:2.4.3

docker run -d \
  --name shenyu-bootstrap \
  --network=host \
  --restart always \
  -v /docker/shenyu/bootstrap/conf:/opt/shenyu-bootstrap/conf \
  apache/shenyu-bootstrap:2.4.3
  
  
docker run \
--name shenyu-admin \
--network=host \
--restart always \
-v /docker/shenyu/admin/ext-lib:/opt/shenyu-admin/ext-lib \
-v /docker/shenyu/admin/conf:/opt/shenyu-admin/conf \
-d \
apache/shenyu-admin:2.4.3

docker run \
--name shenyu-admin \
--network=host \
--restart always \
-v /docker/shenyu/admin/ext-lib:/opt/shenyu-admin/ext-lib \
-e "SPRING_PROFILES_ACTIVE=mysql" \
-e "spring.datasource.url=jdbc:mysql://192.168.50.100:3306/shenyu?useUnicode=true&characterEncoding=utf-8&useSSL=false" \
-e "spring.datasource.username=shenyu" \
-e "spring.datasource.password=ilak@RITA&8865" \
-d \
apache/shenyu-admin:2.4.3
```

# node_exporter
```
tar xvfz node_exporter-1.3.1.linux-amd64.tar.gz


cat > /etc/systemd/system/node_exporter.service << "EOF"
[Unit]
Description=node_export
Documentation=https://github.com/prometheus/node_exporter
 
[Service]
ExecStart=/tools/node_exporter-1.3.1.linux-amd64/node_exporter
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF



# systemctl daemon-reload

# systemctl enable node_exporter

# systemctl start node_exporter

# systemctl status node_exporter 
```
